{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f882871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a52e93d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(signal, sr, n_mfcc=40):\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    return np.concatenate((mfcc_mean, mfcc_std))\n",
    "\n",
    "def extract_zcr(signal):\n",
    "    zcr = librosa.feature.zero_crossing_rate(signal)\n",
    "    return np.array([np.mean(zcr), np.std(zcr)])\n",
    "\n",
    "def extract_teo(signal):\n",
    "    teo = np.zeros(len(signal))\n",
    "    teo[1:-1] = signal[1:-1]**2 - signal[:-2] * signal[2:]\n",
    "    return np.array([np.mean(teo), np.std(teo)])\n",
    "\n",
    "def extract_hnr(signal, sr):\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(signal, fmin=50, fmax=300)\n",
    "    harmonics = f0[~np.isnan(f0)]\n",
    "    if len(harmonics) > 0:\n",
    "        hnr = 10 * np.log10(np.var(harmonics) / (np.var(signal) + 1e-6))\n",
    "    else:\n",
    "        hnr = 0.0  # default if pitch not found\n",
    "    return np.array([hnr])\n",
    "\n",
    "def feature_concatenator(filepath):\n",
    "    signal, sr = librosa.load(filepath, sr=None)\n",
    "\n",
    "    # Optional: trim silence\n",
    "    signal, _ = librosa.effects.trim(signal)\n",
    "\n",
    "    features = []\n",
    "    features.extend(extract_mfcc(signal, sr))\n",
    "    features.extend(extract_zcr(signal))\n",
    "    features.extend(extract_teo(signal))\n",
    "    features.extend(extract_hnr(signal, sr))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb44cb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\AppData\\Local\\Temp\\ipykernel_16412\\837251297.py:20: RuntimeWarning: divide by zero encountered in log10\n",
      "  hnr = 10 * np.log10(np.var(harmonics) / (np.var(signal) + 1e-6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry  Done !\n",
      "disgust  Done !\n",
      "fear  Done !\n",
      "happy  Done !\n",
      "neutral  Done !\n",
      "sad  Done !\n",
      "FEATURE EXTRACTION COMPLETED\n"
     ]
    }
   ],
   "source": [
    "dataset_path=r'D:\\Projects\\MoodMate\\augmented_dataset'\n",
    "all_features=[]\n",
    "all_labels=[]\n",
    "for emotion in  os.listdir(dataset_path):\n",
    "    for audio in os.listdir(os.path.join(dataset_path,emotion)):\n",
    "        file_path=os.path.join(dataset_path,emotion,audio)\n",
    "        extracted_features=feature_concatenator(file_path)\n",
    "\n",
    "        all_features.append(extracted_features)\n",
    "        all_labels.append(emotion)\n",
    "    print(emotion,\" Done !\")\n",
    "\n",
    "X=np.array(all_features)\n",
    "y=np.array(all_labels)\n",
    "\n",
    "df=pd.DataFrame(X)\n",
    "df['label']=y\n",
    "\n",
    "df.to_csv(\"final_extracted_features.csv\",index=False)\n",
    "\n",
    "print(\"FEATURE EXTRACTION COMPLETED\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2528a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
